# 存储器层次结构

## Abstract

关于计算机系统模型，能够将存储器系统视为线性的字节数组，而cpu能够在一个常数内访问任意存储器的位置。

cpu寄存器保存着最常用的数据，靠近cpu小的、快速的高速缓存存储器「cache memory」作为一部分存储在相对较慢的主存「main memory」中数据和指令的缓冲区域。

主缓存存储在**容量较大、慢速磁盘上**的数据；而磁盘经常作为存储**在通过网络连接其他机器磁盘的缓存**

## Cache 基本模型

![image-20210223161622435](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223161622435.png)

cpu通过bus「总线」从主存中取指令和数据，完成计算后再将结果写回内存当中。问题在于：**cpu超级快的运算速度和主存相对慢的特别多的运算速度无法匹配**。使许多时间都浪费在贮存上。即上图所说的：<font color=red>**lots of waiting on memory**</font>

---

因为主存比较慢因此需要尽量减少cpu对主存的访问，于是在cpu和主存之间增加了一层cache **(solutions:cache)**：

![image-20210223162214483](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223162214483.png)

计算机中，cache被访问速度快的计算机内存，用来**保存频繁访问或者最近访问的指令和内存**。

> cache的造价一般较高，相对于memory，其容量比较小，保存的数据也有限

cache主要用来消除cpu和内存之间指令和数据访问的瓶颈，概括一下为：

<img src="/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223162647534.png" alt="image-20210223162647534" style="zoom:50%;" />

## 局部性 -- locality

> 即程序倾向于引用邻近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身，这种倾向性称为**locality**

![image-20210223163234432](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223163234432.png)

局部性原理让cache能更高效地工作，一个编写良好的计算机程序通常都具有良好的局部性（locality）。局部性一般有2种不同的形式：**时间局部性（temporal locality）**和**空间局部性（spatial locality）**。

**`良好的temporal locality：`** 被引用过一次的**内存地址**很可能在不远的将来会**再被多次引用**；

**`良好的spatial locality：`** 如果一个**内存地址**被引用了一次，那么程序可能在不远的将来会引用**附近的一个内存位置**。

<center><font color=red>程序如何利用局部性定理的呢？</font></center>

**Example：**

```c
int sum = 0;
for(int i=0; i<n; ++i){
  sum += a[i];
}
return sum;
```

---

**Discussion:**

**`Datas「数据角度」：`**

- `sum`变量在每次循环迭代时都会被访问，符合`temporal locality`

- 采用`stride=1`的方式访问数组`a[]`，符合`spatial locality`

**`Instructions「指令角度」：`**

- 循环迭代，符合时间局部性
- **线性**地执行命令，符合空间局部性

因此，编写具有良好局部性的程序能让程序运行更快

---

**Summary：**

- 重复引用同一变量的程序有良好的`temporal locality`

- 对于具有步长为`k`的引用模式的程序，步长越小，空间局部性越好
- 对于`instructions`来说，循环体越小，迭代次数越多，`locality`越好

## Memory hierarchy

![image-20210223165654923](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223165654923.png)

**properties：**

- 从高层往低层走：存储设备根据层数的降低，更慢、更便宜和更大
- 最高层「L0」是少量快速的cpu寄存器，cpu能够在**一个时钟周期**内访问他们，接下来是1个或多个小型到中型的基于`SRAM`的高速缓存存储器，可以在**几个cpu时钟周期**内访问他们；然后为一个基于`DRAM`的大的贮存，能够**在几十或者几百个时钟周期**内访问它们。
- 最底层是**慢速但是容量很大**的本地磁盘，有些系统甚至包括了一层附加的远程服务器上的磁盘，需要通过网络来访问他们。如**安德鲁文件**「Andrew File System, AFS」或**网络文件系统**「Network File System，NFS」的分布式文件系统，允许程序**访问存储在远程的网络服务器上的文件**

---

**Design Core**

位于$k$层的更快更小的存储设备作为位于$k+1$层的更大更慢的存储设备的缓存，即在层次结构中每一层的缓存都来自于较低一层的数据对象。

**举个栗子**：本地磁盘作为通过网络从远程磁盘取出文件的缓存，以此类推取出的为$cpu$寄存器

---

## Cache

![image-20210223171204180](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223171204180.png)

如上图所示关于memory hierarchy的一般性概念，第$k+1$层的存储器被划分为连续的数据对象组块（chunk），称为块（block）。

每个块都有一个唯一的名字或者地址来区别其他的块，如第k+1层存储器被划分成了16个大小固定的块，编号为`0~15`。而第k层的缓存包含了第`k+1`层块的一个子集的副本。如在第$k$层的缓存有4个块的控件，当前包含了`8,9,14,3`的副本。

数据总是以块大小为传输单元在第$k$层和第$k+1$层之间来回复制，虽然在层次结构中任何一对相邻的层次之间块大小是固定的，但是对于其他的层次对之间的块的大小是不同的。

如`L1`和`L2`之间的传送通常为几十个字大小的块，而`L5`和`L4`之间传送用的则是大小为几百或几千字节的块。一般来说，层次结构中离cpu较远（较低层）的设备的访问时间较长。因此为了补偿这些较长的访问时间，一般倾向于使用较大的块来扩大存储量。

### Cache HIT --- 缓存命中

> **cold cache**：冷缓存，指空的缓存

![image-20210223172804182](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223172804182.png)

当程序需要第$k+1$层的某个数据对象`d`时，首先会在当前存储在第$k$层的一个块中查找d，如果d刚好缓存在$k$层，则为**缓存命中**。

因为是在第$k$层而非第$k+1$层，读取速度会更快。所以缓存命中的情况能够反映程序的良好时间局部性。

### Cache Miss --- 缓存不命中

![image-20210223173510354](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223173510354.png)

如果第$k$层中没有缓存数据对象$d$，则是我们所说的缓存不命中。当出现cache miss时，第k层的缓存会从第k+1层缓存中取出包含d的块，此时如果第k层的缓存已经满了，也有可能会覆盖现存的块。

如果覆盖了现存的块，这个过程称为**替换「replacing」**或者**驱逐「evicting」**，被替换的块有时也被称为**牺牲块「victim block」**。

决定替换那个块是有缓存的**替换策略**来影响的：

- `随机替换策略`： 随机选择牺牲块
- `LRU:` 选择最后被访问时间离当前最远的块

### Summary

- **利用时间局部性：**因为时间局部性，同一数据对象可能被多次使用，一旦一个数据对象在第一次不命中时被拷贝到缓存中，我们会期望后面对该目标有一系列的访问命中，因为缓存比第一层的存储设备更快，对后面命中的服务会比最开始的不命中快很多。**即提高命中率**
- **利用空间局部性：** 块通常会**包含多个数据对象**，因为空间局部性，希望后面对块中其他对象的访问能够补偿不命中后拷贝该块的花费。

## Cache Memory

早期计算机系统的存储器层次结构只有三层：

1. CPU寄存器
2. DRAM主存储器
3. 磁盘存储

因为cpu和主存之间逐渐增大的速度差异，系统设计者在cpu和主存之间插入了一个小的SRAM的高速缓存存储器，称为L1高速缓存。

而随着cpu和主存之间性能差异逐渐增大，系统设计者在cpu和主存之间插入了一个更大的SRAM，称为L2高速缓存。

![image-20210223175500114](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210223175500114.png)

### General Structure

假设一个计算机系统，每个存储器地址有$m$位，形成$M=2^m$个不同的地址，如图所示，一个机器的高速缓存被组织成一个有$S=2^s$个**高速缓存组（cache set）**的数组。每个组包含$E$个**高速缓存行（cache line）**，每行由$B=2^b$字节的**数据块**组成，一个**有效位「valid bit」**指明这个行是否有效，同时还有$t = m-(s+b)$个**标记位「tab bit」**，他们唯一的标识存储在这个高速缓存行中的块

> ![image-20210224105115391](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210224105115391.png)上图示例为高速缓存$S,E,B,m$的通用组织
>
> 1. 高速缓存为一个高速缓存组的**数组**，每个组包含一个或多个行，这个行包含了一个有效位，一些标记位，以及一个数据块
> 2. 高速缓存的结构将$m$个地址划分为了t个标记为，s个组索引位和b个块偏移位

其中：

- `S:` cache set
- `E:` cache line
- `B:` block，地址的b位的偏移地址确定了要从高速缓存行读出的字节，即偏移b位即为需要读出的字节
- `m:` tag bit

**总结来说即为高速缓存分为组，每组又包含很多行，每行由有效位和标记位以及数据块组成。这样不知道字母对应的哪个项查看即可**

**分析「以上图来解释」：**从组开始，高速缓存分成了多个组，每组包含了多行，分组可以得到数据缓存的大概位置，从图中能够了解到**组索引**专门用来找**到数据缓存的对应组**的；

再探讨行，有效位是用来标记该行的缓存数据的，标记行用于匹配组内的具体行。由图b知道，前t位为标记位。

因此在<font color=red>**查找过程中，先通过组索引找到数据对应缓存的那一组，后根据标记找到数据缓存在哪一行，最后通过块偏移找到数据的起始字节.**</font>

---

<center><font color=green>高速缓存查找流程</font></center>

$$
行选择\Rightarrow 行匹配\Rightarrow 字抽取
$$

---

### Cache Line Classification

根据每个组的高速缓存行数，高速缓存可以分为以下三类：

- **直接映射高速缓存「每组只有一个高速缓存行」**

- **E路组相连高速缓存「每组有E个高速缓存行」**

- **全相连高速缓存「只有一个组」**

#### <1> 直接映射高速缓存(direct-mapped cache)

因为每组只有一个高速缓存行，因此仅需通过组索引即可得到高速缓存行的具体位置，但这不代表数据就缓存在这一行中，还需要**查看有效位是否置位，并且需要对比标记为是否相同**，当这几个条件都满足了，才能代表数据缓存在该行中，之后再通过块偏移找到数据的起始字节并取出。如图：

![image-20210224111307289](/Users/zoriswang/Library/Application Support/typora-user-images/image-20210224111307289.png)

> 块偏移位「b位」提供了所需要的字的第一个字节的偏移。这样类似于我们把高速缓存看成一个行的数组一样，我们把块看成**一个字节的数组**，而**字节偏移**是到这个数组的一个**索引**

当发生`chche miss`时，因为每组只有一行，用新取出的行替换当前行即可。

#### <2> 组相连高速缓存(set associative cache)

**特点：** 与直接映射高速缓存寻找组一样，都是通过组索引寻找，但是寻找高速缓存行的方式不同，因为组相连高速缓存**每组有多行**，因此高速缓存需要**寻找组内和地址的标记位**相同的行.

当发生不命中时，需要使用替换策略。

#### <3> 全相连高速缓存(fully associative cache)

**特点：** 全相连高速缓存中，地址没有组索引这一项，因为其只有一个组，不需要索引；其他的步骤和组相连高速缓存一样。

因为**全相连高速缓存**只有一个组，当高速缓存行多了的时候，此时找起来是十分费力的，因此它**只适合做小的高速缓存**，如需你存储器系统中的翻译备用缓存器$TLB$

### Influenced Factors

1. **高速缓存的大小：** 大缓存可以提高命中率，但是会增加命中时间

2. **块大小：** 大的块可以利用程序中可能存在的空间局部性，提高命中率。但是因为块大会使传送的时间增加，因此如果发生了不命中，代价会十分大

3. **相联度：** 相联度高能够降低高速缓存发生冲突不命中时出现抖动的可能性，但是会增加命中时间「因为需要查找标记位」，以及替换策略的复杂性也增加了

4. **写策略：** 当高速缓存中更新了一个数据时，要接着更新第一层中该数据时，就进行了写的操作：

   - 采用**直写操作：** 即直接更新该数据，这样虽然简单，但会出现即使该数据没有被使用，而数据每次都会在总线上传输
   - 采用**写回策略：** 即当前层的这个数据对应的行要被替换了，才更新低一层的该数据，这样可以降低总线流量，但是复杂性变高了，因为这种方法不得不在高速缓存行上添加一位是否被修改的位。
   - **写不命中**时采用**写分配**： 加载相应第一层中的块到高速缓存中，之后更新这个高速缓存块。

   > 高速缓存中，如果采用直写，会增加传送数据的时间；因此在低层次的存储器中，一般采用写回。



